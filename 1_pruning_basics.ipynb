{"cells":[{"cell_type":"markdown","source":["# **Embedded AI workshop**\n","## **Basics of Pruning**\n","### *Mohammmad Ali Zamani*\n","\n","*Senior Machine Learning Scientist at HITeC e.V.*\n","\n","homepage: [zamani.ai](https://zamani.ai/)\n","\n","This notebook is the simplified version of [Pytorch tutorial for pruning](https://pytorch.org/tutorials/intermediate/pruning_tutorial.html)\n"],"metadata":{"id":"tjEdUh94Gqje"}},{"cell_type":"markdown","metadata":{"id":"uZ3PCtZwb9DW"},"source":["Pruning Tutorial\n","================\n","\n","**Author**: [Michela Paganini](https://github.com/mickypaganini)\n","\n","State-of-the-art deep learning techniques rely on over-parametrized\n","models that are hard to deploy. On the contrary, biological neural\n","networks are known to use efficient sparse connectivity. Identifying\n","optimal techniques to compress models by reducing the number of\n","parameters in them is important in order to reduce memory, battery, and\n","hardware consumption without sacrificing accuracy. This in turn allows\n","you to deploy lightweight models on device, and guarantee privacy with\n","private on-device computation. On the research front, pruning is used to\n","investigate the differences in learning dynamics between\n","over-parametrized and under-parametrized networks, to study the role of\n","lucky sparse subnetworks and initializations (\\\"[lottery\n","tickets](https://arxiv.org/abs/1803.03635)\\\") as a destructive neural\n","architecture search technique, and more.\n","\n","In this tutorial, you will learn how to use `torch.nn.utils.prune` to\n","sparsify your neural networks, and how to extend it to implement your\n","own custom pruning technique.\n","\n","Requirements\n","------------\n","\n","`\"torch>=1.4.0a0+8e8a5e0\"`\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_FMdogqvb9Dc"},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.nn.utils.prune as prune\n","import torch.nn.functional as F"]},{"cell_type":"markdown","metadata":{"id":"9Ve76Yvxb9De"},"source":["Create a model\n","==============\n","\n","In this tutorial, we use the\n","[LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf) architecture\n","from LeCun et al., 1998.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C84tDHaSb9De"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class LeNet(nn.Module):\n","    def __init__(self):\n","        super(LeNet, self).__init__()\n","        # 1 input image channel, 6 output channels, 5x5 square conv kernel\n","        self.conv1 = nn.Conv2d(1, 6, 5)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5x5 image dimension\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n","        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n","        x = x.view(-1, int(x.nelement() / x.shape[0]))\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"a0FtNu15b9Df"},"source":["Inspect a Module\n","================\n","\n","Let\\'s inspect the (unpruned) `conv1` layer in our LeNet model. It will\n","contain two parameters `weight` and `bias`, and no buffers, for now.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"chqqOMMab9Dg"},"outputs":[],"source":["model = LeNet().to(device=device)\n","module = model.conv1\n","print(\"weight:\")\n","print(module.weight)\n","print(\"bias:\")\n","print(module.bias)"]},{"cell_type":"markdown","metadata":{"id":"2KDvbqmlb9Di"},"source":["Pruning a Module\n","================\n","\n","To prune a module (in this example, the `conv1` layer of our LeNet\n","architecture), first select a pruning technique among those available in\n","`torch.nn.utils.prune` (or\n","[implement](#extending-torch-nn-utils-pruning-with-custom-pruning-functions)\n","your own by subclassing `BasePruningMethod`). Then, specify the module\n","and the name of the parameter to prune within that module. Finally,\n","using the adequate keyword arguments required by the selected pruning\n","technique, specify the pruning parameters.\n","\n","In this example, we will prune at random 30% of the connections in the\n","parameter named `weight` in the `conv1` layer. The module is passed as\n","the first argument to the function; `name` identifies the parameter\n","within that module using its string identifier; and `amount` indicates\n","either the percentage of connections to prune (if it is a float between\n","0. and 1.), or the absolute number of connections to prune (if it is a\n","non-negative integer).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ffGjsy0nb9Dj"},"outputs":[],"source":["prune.random_unstructured(module, name=\"weight\", amount=0.3)"]},{"cell_type":"markdown","metadata":{"id":"BTkcH8Ugb9Dk"},"source":["Pruning only affected `weight` by removing about 30% of the parameters. The `bias` was not pruned, so it will remain intact.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CRXMAH5Vb9Dk"},"outputs":[],"source":["print(\"weight:\")\n","print(module.weight)\n","print(\"bias:\")\n","print(module.bias)"]},{"cell_type":"markdown","metadata":{"id":"7qMxOL81b9Do"},"source":["For completeness, we can now prune the `bias` too, to see how the\n","parameters, buffers, hooks, and attributes of the `module` change. Just\n","for the sake of trying out another pruning technique, here we prune the\n","3 smallest entries in the bias by L1 norm, as implemented in the\n","`l1_unstructured` pruning function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BcZZf6DJb9Dp"},"outputs":[],"source":["prune.l1_unstructured(module, name=\"bias\", amount=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VpY_m9qob9Dq"},"outputs":[],"source":["print(module.bias)"]},{"cell_type":"markdown","metadata":{"id":"BIl2W3T0b9Ds"},"source":["Structured Pruning\n","=================\n","\n","We now want to prune `module.weight`,\n","this time using structured pruning along the 0th axis of the tensor (the\n","0th axis corresponds to the output channels of the convolutional layer\n","and has dimensionality 6 for `conv1`), based on the channels\\' L2 norm.\n","This can be achieved using the `ln_structured` function, with `n=2` and\n","`dim=0`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dj_lIIUtb9Dt"},"outputs":[],"source":["model = LeNet()\n","module = model.conv1\n","prune.ln_structured(module, name=\"weight\", amount=0.5, n=2, dim=0)\n","\n","# As we can verify, this will zero out all the connections corresponding to\n","# 50% (3 out of 6) of the channels, while preserving the action of the\n","# previous mask.\n","print(\"after pruning:\")\n","print(module.weight)\n","\n","# TODO, prune the weights with different amount and dimension"]},{"cell_type":"markdown","metadata":{"id":"c5Yg7OT0b9D9"},"source":["Pruning multiple parameters in a model\n","======================================\n","\n","By specifying the desired pruning technique and parameters, we can\n","easily prune multiple tensors in a network, perhaps according to their\n","type, as we will see in this example.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jq3ZZYNUb9D-"},"outputs":[],"source":["new_model = LeNet()\n","for name, module in new_model.named_modules():\n","    # prune 20% of connections in all 2D-conv layers\n","    if isinstance(module, torch.nn.Conv2d):\n","        prune.ln_structured(module, name='weight', amount=0.2, n=2, dim=0)\n","    # prune 40% of connections in all linear layers\n","    elif isinstance(module, torch.nn.Linear):\n","        prune.l1_unstructured(module, name='weight', amount=0.4)\n","\n","print(new_model.conv1.weight)\n","print(new_model.fc3.weight)"]},{"cell_type":"markdown","metadata":{"id":"M-67CzhEb9EB"},"source":["Global pruning\n","==============\n","\n","So far, we only looked at what is usually referred to as \\\"local\\\"\n","pruning, i.e. the practice of pruning tensors in a model one by one, by\n","comparing the statistics (weight magnitude, activation, gradient, etc.)\n","of each entry exclusively to the other entries in that tensor. However,\n","a common and perhaps more powerful technique is to prune the model all\n","at once, by removing (for example) the lowest 20% of connections across\n","the whole model, instead of removing the lowest 20% of connections in\n","each layer. This is likely to result in different pruning percentages\n","per layer. Let\\'s see how to do that using `global_unstructured` from\n","`torch.nn.utils.prune`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5mC6WcjAb9EB"},"outputs":[],"source":["model = LeNet()\n","\n","parameters_to_prune = (\n","    (model.conv1, 'weight'),\n","    (model.conv2, 'weight'),\n","    (model.fc1, 'weight'),\n","    (model.fc2, 'weight'),\n","    (model.fc3, 'weight'),\n",")\n","\n","prune.global_unstructured(\n","    parameters_to_prune,\n","    pruning_method=prune.L1Unstructured,\n","    amount=0.2,\n",")"]},{"cell_type":"markdown","metadata":{"id":"8Dy8xpABb9EC"},"source":["Now we can check the sparsity induced in every pruned parameter, which\n","will not be equal to 20% in each layer. However, the global sparsity\n","will be (approximately) 20%.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pq8axqLob9EC"},"outputs":[],"source":["print(\n","    \"Sparsity in conv1.weight: {:.2f}%\".format(\n","        100. * float(torch.sum(model.conv1.weight == 0))\n","        / float(model.conv1.weight.nelement())\n","    )\n",")\n","print(\n","    \"Sparsity in conv2.weight: {:.2f}%\".format(\n","        100. * float(torch.sum(model.conv2.weight == 0))\n","        / float(model.conv2.weight.nelement())\n","    )\n",")\n","print(\n","    \"Sparsity in fc1.weight: {:.2f}%\".format(\n","        100. * float(torch.sum(model.fc1.weight == 0))\n","        / float(model.fc1.weight.nelement())\n","    )\n",")\n","print(\n","    \"Sparsity in fc2.weight: {:.2f}%\".format(\n","        100. * float(torch.sum(model.fc2.weight == 0))\n","        / float(model.fc2.weight.nelement())\n","    )\n",")\n","print(\n","    \"Sparsity in fc3.weight: {:.2f}%\".format(\n","        100. * float(torch.sum(model.fc3.weight == 0))\n","        / float(model.fc3.weight.nelement())\n","    )\n",")\n","print(\n","    \"Global sparsity: {:.2f}%\".format(\n","        100. * float(\n","            torch.sum(model.conv1.weight == 0)\n","            + torch.sum(model.conv2.weight == 0)\n","            + torch.sum(model.fc1.weight == 0)\n","            + torch.sum(model.fc2.weight == 0)\n","            + torch.sum(model.fc3.weight == 0)\n","        )\n","        / float(\n","            model.conv1.weight.nelement()\n","            + model.conv2.weight.nelement()\n","            + model.fc1.weight.nelement()\n","            + model.fc2.weight.nelement()\n","            + model.fc3.weight.nelement()\n","        )\n","    )\n",")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"colab":{"provenance":[{"file_id":"https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/7126bf7beed4c4c3a05bcc2dac8baa3c/pruning_tutorial.ipynb","timestamp":1715696210218}]}},"nbformat":4,"nbformat_minor":0}